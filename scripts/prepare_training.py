#!/usr/bin/env python3
"""–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""

import os
import json
import yaml
from pathlib import Path
from typing import Dict, List, Tuple
import shutil
import cv2
import numpy as np

def validate_dataset(data_dir: str, annotation_file: str) -> Dict[str, any]:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    with open(annotation_file, 'r', encoding='utf-8') as f:
        coco_data = json.load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    images = {}
    missing_images = []
    valid_images = 0
    
    for img_info in coco_data['images']:
        img_path = os.path.join(data_dir, img_info['file_name'])
        if os.path.exists(img_path):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–∏—Ç–∞–µ—Ç—Å—è
            image = cv2.imread(img_path)
            if image is not None:
                height, width = image.shape[:2]
                images[img_info['id']] = {
                    'path': img_path,
                    'actual_size': (width, height),
                    'expected_size': (img_info['width'], img_info['height']),
                    'valid': True
                }
                valid_images += 1
            else:
                images[img_info['id']] = {'valid': False, 'error': 'Cannot read image'}
        else:
            missing_images.append(img_info['file_name'])
            images[img_info['id']] = {'valid': False, 'error': 'File not found'}
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_stats = {}
    for cat in coco_data['categories']:
        category_stats[cat['id']] = {
            'name': cat['name'],
            'count': 0
        }
    
    # –ü–æ–¥—Å—á—ë—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    valid_annotations = 0
    for ann in coco_data['annotations']:
        if ann['image_id'] in images and images[ann['image_id']]['valid']:
            category_stats[ann['category_id']]['count'] += 1
            valid_annotations += 1
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    validation_results = {
        'total_images': len(coco_data['images']),
        'valid_images': valid_images,
        'missing_images': missing_images,
        'total_annotations': len(coco_data['annotations']),
        'valid_annotations': valid_annotations,
        'category_distribution': category_stats,
        'images_info': images
    }
    
    # –û—Ç—á—ë—Ç
    print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {valid_images}/{len(coco_data['images'])}")
    print(f"‚úÖ –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: {valid_annotations}/{len(coco_data['annotations'])}")
    
    if missing_images:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {missing_images}")
    
    print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat_id, stats in category_stats.items():
        print(f"  {stats['name']}: {stats['count']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
    
    return validation_results

def create_train_val_split(data_dir: str, train_ratio: float = 0.7) -> Tuple[List[str], List[str]]:
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è train/val"""
    
    print(f"\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è train/val (ratio: {train_ratio})")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    image_files.sort()
    
    # –†–∞–∑–±–∏–µ–Ω–∏–µ
    n_train = int(len(image_files) * train_ratio)
    train_files = image_files[:n_train]
    val_files = image_files[n_train:]
    
    print(f"üì¶ Train: {len(train_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"üì¶ Val: {len(val_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    for f in train_files:
        print(f"  Train: {f}")
    for f in val_files:
        print(f"  Val: {f}")
    
    return train_files, val_files

def create_yolo_annotations(coco_file: str, output_dir: str, image_dir: str):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO"""
    
    print(f"\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ {output_dir}")
    
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(output_dir, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º COCO –¥–∞–Ω–Ω—ã–µ
    with open(coco_file, 'r', encoding='utf-8') as f:
        coco_data = json.load(f)
    
    # –°–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    images_map = {img['id']: img for img in coco_data['images']}
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    annotations_by_image = {}
    for ann in coco_data['annotations']:
        if ann['image_id'] not in annotations_by_image:
            annotations_by_image[ann['image_id']] = []
        annotations_by_image[ann['image_id']].append(ann)
    
    # –°–æ–∑–¥–∞—ë–º YOLO —Ñ–∞–π–ª—ã
    for img_id, img_info in images_map.items():
        txt_filename = os.path.splitext(img_info['file_name'])[0] + '.txt'
        txt_path = os.path.join(output_dir, txt_filename)
        
        with open(txt_path, 'w') as f:
            if img_id in annotations_by_image:
                for ann in annotations_by_image[img_id]:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bbox –≤ YOLO —Ñ–æ—Ä–º–∞—Ç
                    x, y, w, h = ann['bbox']
                    img_w, img_h = img_info['width'], img_info['height']
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                    x_center = (x + w/2) / img_w
                    y_center = (y + h/2) / img_h
                    width = w / img_w
                    height = h / img_h
                    
                    # YOLO format: class x_center y_center width height
                    f.write(f"{ann['category_id']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(images_map)} YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")

def create_training_config(project_dir: str, train_files: List[str], val_files: List[str]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    
    print(f"\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è")
    
    config = {
        'model_config': {
            'architecture': 'yolov8n',  # –õ—ë–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
            'num_classes': 6,
            'input_size': 640,
            'pretrained': True
        },
        'training_config': {
            'batch_size': 4,  # –ú–∞–ª–µ–Ω—å–∫–∏–π batch –¥–ª—è 7 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            'epochs': 100,
            'learning_rate': 0.001,
            'weight_decay': 0.0005,
            'patience': 20,
            'save_best_only': True,
            'early_stopping': True
        },
        'data_config': {
            'dataset_path': 'data/curated',
            'annotation_path': 'data/annotations/coco/instances.json',
            'train_files': train_files,
            'val_files': val_files,
            'num_workers': 2,
            'pin_memory': True
        },
        'augmentation_config': {
            'horizontal_flip': 0.5,
            'vertical_flip': 0.1,
            'rotation': 10,
            'brightness': 0.2,
            'contrast': 0.2,
            'saturation': 0.2,
            'hue': 0.1,
            'mosaic': 0.3,
            'mixup': 0.1
        },
        'loss_config': {
            'use_knout_pryanik': True,
            'focal_loss_alpha': 0.25,
            'focal_loss_gamma': 2.0,
            'box_loss_gain': 7.5,
            'cls_loss_gain': 0.5,
            'obj_loss_gain': 1.0
        },
        'validation_config': {
            'conf_threshold': 0.25,
            'iou_threshold': 0.45,
            'save_predictions': True,
            'visualize_results': True
        },
        'logging_config': {
            'log_level': 'INFO',
            'log_interval': 10,
            'save_checkpoints': True,
            'tensorboard_logging': True,
            'wandb_logging': False
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_path = os.path.join(project_dir, 'configs', 'training_config.yaml')
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {config_path}")
    
    return config

def create_dataset_yaml(project_dir: str):
    """–°–æ–∑–¥–∞–Ω–∏–µ dataset.yaml –¥–ª—è YOLOv8"""
    
    dataset_config = {
        'path': '/Users/bekzat/projects/AIinDrive/data/curated',
        'train': 'train',  # –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç path
        'val': 'val',      # –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç path
        'nc': 6,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        'names': {
            0: 'no_damage',
            1: 'rust', 
            2: 'dent',
            3: 'scratch',
            4: 'severe_damage',
            5: 'missing_part'
        }
    }
    
    dataset_path = os.path.join(project_dir, 'data', 'dataset.yaml')
    with open(dataset_path, 'w', encoding='utf-8') as f:
        yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    print(f"‚úÖ Dataset config —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {dataset_path}")
    return dataset_path

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏"""
    
    project_dir = "/Users/bekzat/projects/AIinDrive"
    data_dir = os.path.join(project_dir, "data", "curated")
    annotation_file = os.path.join(project_dir, "data", "annotations", "coco", "instances.json")
    
    print("üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ AIinDrive")
    print("=" * 60)
    
    # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    validation_results = validate_dataset(data_dir, annotation_file)
    
    if validation_results['valid_images'] == 0:
        print("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return
    
    # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è train/val
    train_files, val_files = create_train_val_split(data_dir, train_ratio=0.7)
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    yolo_annotations_dir = os.path.join(project_dir, "data", "annotations", "yolo")
    create_yolo_annotations(annotation_file, yolo_annotations_dir, data_dir)
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    config = create_training_config(project_dir, train_files, val_files)
    
    # 5. –°–æ–∑–¥–∞–Ω–∏–µ dataset.yaml
    dataset_yaml_path = create_dataset_yaml(project_dir)
    
    print("\n" + "=" * 60)
    print("‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ")
    print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ: python scripts/train.py")
    print("3. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ—Ü–µ—Å—Å —á–µ—Ä–µ–∑ TensorBoard")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    results_path = os.path.join(project_dir, "data", "validation_results.json")
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(validation_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_path}")

if __name__ == "__main__":
    main()
