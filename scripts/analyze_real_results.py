#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import argparse
import json
import os
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd


class RealResultsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, results_dir: str):
        self.results_dir = Path(results_dir)
        self.results_data = []
        self.load_results()
    
    def load_results(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ {self.results_dir}")
        
        # –ò—â–µ–º –≤—Å–µ JSON —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        result_files = list(self.results_dir.rglob("*_result.json"))
        batch_files = list(self.results_dir.rglob("batch_results.json"))
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(result_files)} –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(batch_files)} –ø–∞–∫–µ—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result_file in result_files:
            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    data['source_file'] = str(result_file)
                    self.results_data.append(data)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {result_file}: {e}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞–∫–µ—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for batch_file in batch_files:
            try:
                with open(batch_file, 'r', encoding='utf-8') as f:
                    batch_data = json.load(f)
                    for result in batch_data.get('results', []):
                        result['source_file'] = str(batch_file)
                        self.results_data.append(result)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {batch_file}: {e}")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.results_data)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    def generate_summary_stats(self) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if not self.results_data:
            return {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        damage_levels = [r['predictions']['damage_level'] for r in self.results_data]
        confidences = [r['predictions']['confidence'] for r in self.results_data]
        processing_times = [r['predictions']['processing_time'] for r in self.results_data]
        
        # –¢–∏–ø—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        all_damage_types = []
        for r in self.results_data:
            all_damage_types.extend(r['predictions'].get('damage_types', []))
        
        # –†–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_sizes = []
        for r in self.results_data:
            size = r['metadata'].get('image_size', [0, 0])
            if len(size) >= 2:
                image_sizes.append(size[0] * size[1])  # –ø–ª–æ—â–∞–¥—å
        
        stats = {
            'total_images': len(self.results_data),
            'damage_level_distribution': dict(Counter(damage_levels)),
            'confidence_stats': {
                'mean': sum(confidences) / len(confidences) if confidences else 0,
                'min': min(confidences) if confidences else 0,
                'max': max(confidences) if confidences else 0,
                'below_50': sum(1 for c in confidences if c < 0.5),
                'above_90': sum(1 for c in confidences if c > 0.9)
            },
            'processing_time_stats': {
                'mean': sum(processing_times) / len(processing_times) if processing_times else 0,
                'min': min(processing_times) if processing_times else 0,
                'max': max(processing_times) if processing_times else 0
            },
            'damage_types_frequency': dict(Counter(all_damage_types)),
            'image_size_stats': {
                'mean_area': sum(image_sizes) / len(image_sizes) if image_sizes else 0,
                'min_area': min(image_sizes) if image_sizes else 0,
                'max_area': max(image_sizes) if image_sizes else 0
            }
        }
        
        return stats
    
    def create_visualizations(self, output_dir: str):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        if not self.results_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è pandas
        df_data = []
        for r in self.results_data:
            df_data.append({
                'image_name': r['image_name'],
                'damage_level': r['predictions']['damage_level'],
                'confidence': r['predictions']['confidence'],
                'processing_time': r['predictions']['processing_time'],
                'num_damage_types': len(r['predictions'].get('damage_types', [])),
                'has_bbox': len(r['predictions'].get('bboxes', [])) > 0
            })
        
        df = pd.DataFrame(df_data)
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        plt.figure(figsize=(10, 6))
        damage_counts = df['damage_level'].value_counts().sort_index()
        
        plt.subplot(2, 2, 1)
        damage_counts.plot(kind='bar', color='skyblue')
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π')
        plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π')
        plt.xticks([0, 1, 2, 3], ['–ù–µ—Ç', '–õ–µ–≥–∫–∏–µ', '–°—Ä–µ–¥–Ω–∏–µ', '–°–µ—Ä—å–µ–∑–Ω—ã–µ'], rotation=45)
        
        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ confidence
        plt.subplot(2, 2, 2)
        plt.hist(df['confidence'], bins=20, alpha=0.7, color='lightgreen')
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏')
        plt.xlabel('Confidence')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        plt.axvline(df['confidence'].mean(), color='red', linestyle='--', 
                   label=f'–°—Ä–µ–¥–Ω–µ–µ: {df["confidence"].mean():.3f}')
        plt.legend()
        
        # 3. –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        plt.subplot(2, 2, 3)
        plt.hist(df['processing_time'], bins=15, alpha=0.7, color='orange')
        plt.title('–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
        plt.xlabel('–í—Ä–µ–º—è (—Å–µ–∫)')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        plt.axvline(df['processing_time'].mean(), color='red', linestyle='--',
                   label=f'–°—Ä–µ–¥–Ω–µ–µ: {df["processing_time"].mean():.3f}—Å')
        plt.legend()
        
        # 4. –°–≤—è–∑—å confidence –∏ damage level
        plt.subplot(2, 2, 4)
        sns.boxplot(data=df, x='damage_level', y='confidence')
        plt.title('Confidence –ø–æ —É—Ä–æ–≤–Ω—è–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π')
        plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è')
        plt.ylabel('Confidence')
        plt.xticks([0, 1, 2, 3], ['–ù–µ—Ç', '–õ–µ–≥–∫–∏–µ', '–°—Ä–µ–¥–Ω–∏–µ', '–°–µ—Ä—å–µ–∑–Ω—ã–µ'])
        
        plt.tight_layout()
        plt.savefig(output_path / 'analysis_overview.png', dpi=300, bbox_inches='tight')
        print(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {output_path / 'analysis_overview.png'}")
        plt.close()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∏–ø—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        damage_types_data = []
        for r in self.results_data:
            for damage_type in r['predictions'].get('damage_types', []):
                damage_types_data.append({
                    'damage_type': damage_type,
                    'damage_level': r['predictions']['damage_level'],
                    'confidence': r['predictions']['confidence']
                })
        
        if damage_types_data:
            df_damage_types = pd.DataFrame(damage_types_data)
            
            plt.figure(figsize=(12, 8))
            
            # –ß–∞—Å—Ç–æ—Ç–∞ —Ç–∏–ø–æ–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
            plt.subplot(2, 2, 1)
            damage_type_counts = df_damage_types['damage_type'].value_counts()
            damage_type_counts.plot(kind='bar', color='coral')
            plt.title('–ß–∞—Å—Ç–æ—Ç–∞ —Ç–∏–ø–æ–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π')
            plt.xlabel('–¢–∏–ø –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è')
            plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            plt.xticks(rotation=45)
            
            # –°–≤—è–∑—å —Ç–∏–ø–æ–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –∏ —É—Ä–æ–≤–Ω–µ–π
            plt.subplot(2, 2, 2)
            damage_crosstab = pd.crosstab(df_damage_types['damage_type'], 
                                        df_damage_types['damage_level'])
            sns.heatmap(damage_crosstab, annot=True, fmt='d', cmap='Blues')
            plt.title('–¢–∏–ø—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π √ó –£—Ä–æ–≤–Ω–∏')
            plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è')
            plt.ylabel('–¢–∏–ø –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è')
            
            plt.tight_layout()
            plt.savefig(output_path / 'damage_types_analysis.png', dpi=300, bbox_inches='tight')
            print(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {output_path / 'damage_types_analysis.png'}")
            plt.close()
    
    def generate_report(self, output_file: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        stats = self.generate_summary_stats()
        
        report = []
        report.append("=" * 80)
        report.append("–û–¢–ß–ï–¢ –ü–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ –ù–ê –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•")
        report.append("=" * 80)
        report.append(f"–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['total_images']}")
        report.append("")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        report.append("–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –£–†–û–í–ù–ï–ô –ü–û–í–†–ï–ñ–î–ï–ù–ò–ô:")
        damage_labels = {0: "–ù–µ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π", 1: "–õ–µ–≥–∫–∏–µ", 2: "–°—Ä–µ–¥–Ω–∏–µ", 3: "–°–µ—Ä—å–µ–∑–Ω—ã–µ"}
        for level, count in sorted(stats['damage_level_distribution'].items()):
            percentage = count / stats['total_images'] * 100
            report.append(f"  {damage_labels.get(level, f'–£—Ä–æ–≤–µ–Ω—å {level}')}: {count} ({percentage:.1f}%)")
        report.append("")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        conf_stats = stats['confidence_stats']
        report.append("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –£–í–ï–†–ï–ù–ù–û–°–¢–ò –ú–û–î–ï–õ–ò:")
        report.append(f"  –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_stats['mean']:.3f}")
        report.append(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: {conf_stats['min']:.3f}")
        report.append(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: {conf_stats['max']:.3f}")
        report.append(f"  –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (<0.5): {conf_stats['below_50']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        report.append(f"  –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>0.9): {conf_stats['above_90']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        report.append("")
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        perf_stats = stats['processing_time_stats']
        report.append("–ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
        report.append(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {perf_stats['mean']:.3f} —Å–µ–∫")
        report.append(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {perf_stats['min']:.3f} —Å–µ–∫")
        report.append(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {perf_stats['max']:.3f} —Å–µ–∫")
        report.append("")
        
        # –¢–∏–ø—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        if stats['damage_types_frequency']:
            report.append("–ß–ê–°–¢–û–¢–ê –¢–ò–ü–û–í –ü–û–í–†–ï–ñ–î–ï–ù–ò–ô:")
            for damage_type, count in sorted(stats['damage_types_frequency'].items(), 
                                           key=lambda x: x[1], reverse=True):
                report.append(f"  {damage_type}: {count}")
            report.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        
        if conf_stats['below_50'] > stats['total_images'] * 0.2:
            report.append("  ‚ö†Ô∏è  –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é")
            report.append("      ‚Üí –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
        
        if perf_stats['mean'] > 1.0:
            report.append("  ‚ö†Ô∏è  –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            report.append("      ‚Üí –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π –º–æ–¥–µ–ª–∏")
        
        no_damage_ratio = stats['damage_level_distribution'].get(0, 0) / stats['total_images']
        if no_damage_ratio > 0.8:
            report.append("  ‚ÑπÔ∏è  –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
            report.append("      ‚Üí –£–±–µ–¥–∏—Ç–µ—Å—å –≤ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏")
        
        report.append("")
        report.append("=" * 80)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print(f"üìù –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é –≤–µ—Ä—Å–∏—é –≤ –∫–æ–Ω—Å–æ–ª—å
        print("\n" + "\n".join(report[:25]) + "\n...")


def main():
    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--results-dir", type=str, 
                       default="data/real_test_cases/results",
                       help="–ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
    parser.add_argument("--output-dir", type=str,
                       default="data/real_test_cases/analysis",
                       help="–ü–∞–ø–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤")
    
    args = parser.parse_args()
    
    # –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
    project_root = Path(__file__).parent.parent
    results_dir = project_root / args.results_dir
    output_dir = project_root / args.output_dir
    
    if not results_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {results_dir}")
        print(f"üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:")
        print(f"   python scripts/test_real_cases.py")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = RealResultsAnalyzer(str(results_dir))
    
    if not analyzer.results_data:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    analyzer.create_visualizations(str(output_dir))
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
    report_file = output_dir / "analysis_report.txt"
    analyzer.generate_report(str(report_file))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ JSON
    stats = analyzer.generate_summary_stats()
    stats_file = output_dir / "detailed_stats.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: {output_dir}")
    print(f"üìä –ì—Ä–∞—Ñ–∏–∫–∏: analysis_overview.png, damage_types_analysis.png")
    print(f"üìù –û—Ç—á–µ—Ç: analysis_report.txt")
    print(f"üìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: detailed_stats.json")


if __name__ == "__main__":
    main()
